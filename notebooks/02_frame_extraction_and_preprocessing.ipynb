{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53de594-7ffc-4f85-bbc4-301fdea3fee1",
   "metadata": {},
   "source": [
    "# FRAME EXTRACTION AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565f4da-b860-4713-bcdd-6233e5adb23c",
   "metadata": {},
   "source": [
    "This notebook aims to explore the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b59e3a-eeed-46ac-aea6-0c230bcf24dd",
   "metadata": {},
   "source": [
    "We will start by using _cv2_ to test the correct installation done in [primer notebook](01_data_download_and_exploration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02be1fa3-3c37-4f07-b38b-33eb32d8a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Dataset path\n",
    "train_dataset_path = \"../data/mvfouls/train_720p\"\n",
    "\n",
    "# Ejemplo de videos del set de entrenamiento\n",
    "training_videos_path = os.path.join(train_dataset_path)\n",
    "example_video = os.path.join(training_videos_path, \"action_1/clip_0.mp4\")\n",
    "\n",
    "# Funci√≥n para visualizar un video\n",
    "def visualize_video(video_path, num_frames=100):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"No se pudo abrir el video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened() and frame_count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Fin del video o error al leer el frame.\")\n",
    "            break\n",
    "        \n",
    "        cv2.imshow('Video Frame', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):  # Presiona 'q' para salir\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "visualize_video(example_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d193ef0-7ec2-458f-8be5-3ce89c8f561f",
   "metadata": {},
   "source": [
    "Once we are sured the dataset has been installed correctly, we can continue. As we know thanks to the [callenge's paper](https://arxiv.org/abs/2304.04617), each clip longs 5 second, consisting of 3 seconds before and 2 seconds after the timestamp which leaves the action between frame 63 and frame 87. \n",
    "\n",
    "We will now explore each **type of action**:\n",
    "- Standing tackling\n",
    "- Tackling\n",
    "- Challenge\n",
    "- Holding\n",
    "- Elbowing\n",
    "- High leg\n",
    "- Pushing\n",
    "- Dive\n",
    "\n",
    "We will now count how many are of each types in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45721a58-b52d-407f-a233-4c1ccf666549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foul types and its frequency:\n",
      "Challenge: 383\n",
      "Tackling: 448\n",
      "Standing tackling: 1264\n",
      "High leg: 103\n",
      "Dive: 28\n",
      "Elbowing: 178\n",
      ": 11\n",
      "Holding: 361\n",
      "Dont know: 52\n",
      "Pushing: 88\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "labels_path = os.path.join(train_dataset_path, \"annotations.json\")\n",
    "\n",
    "with open(labels_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "types = []\n",
    "\n",
    "for action_index, action_data in data['Actions'].items():\n",
    "    type = action_data['Action class']\n",
    "    types.append(type)\n",
    "\n",
    "types_count = Counter(types)\n",
    "\n",
    "sum = 0\n",
    "\n",
    "print(\"Foul types and its frequency:\")\n",
    "for t, count in types_count.items():\n",
    "    sum += 1\n",
    "    print(f\"{t}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5d68f-9af1-434b-aa88-dee3c7fcc5a8",
   "metadata": {},
   "source": [
    "As we see there are some marked as \"_Don't know_\" or \"\", wich may be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d885e-b8fd-40dd-bc01-8fb99b9613d1",
   "metadata": {},
   "source": [
    "We will now show an example for each type of action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cce33072-0716-46c7-8b9c-9d0af1dc435e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "labels_path = os.path.join(train_dataset_path, \"annotations.json\")\n",
    "\n",
    "with open(labels_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "action_type = \"Pushing\"\n",
    "action_paths = []\n",
    "\n",
    "for action_index, action_data in data['Actions'].items():\n",
    "    if action_data['Action class'] == action_type:\n",
    "        action_clips = action_data['Clips']\n",
    "        for action in action_clips:\n",
    "            action_paths.append(action['Url'])\n",
    "        break\n",
    "\n",
    "dataset_path = \"../data/mvfouls/train_720p/\"\n",
    "\n",
    "corrected_action_paths = [path.replace('Dataset/Train/', dataset_path) for path in action_paths]\n",
    "corrected_action_paths = [path if path.endswith('.mp4') else path + \".mp4\" for path in corrected_action_paths]\n",
    "\n",
    "for video in corrected_action_paths:\n",
    "    visualize_video(video)\n",
    "\n",
    "action_paths.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

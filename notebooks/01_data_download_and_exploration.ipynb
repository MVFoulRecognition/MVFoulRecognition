{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02343a19-8f8f-4a54-a5a1-f9cc0448c123",
   "metadata": {},
   "source": [
    "# DATA DOWNLOAD AND EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a8789-92a8-4c50-a678-c4a150a1a5c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This first notebook will cover the **installation** of the dataset to be used. This dataset is provided by _SoccerNet_ and contains over 3.000 multi-view videos for training, validation and testing, and provides 273 actions for the challenge.\n",
    "\n",
    "We start by installing the __SoccerNet-v2__, wich will provide us the necessary tools for the download of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e87e29-c6a4-421e-9af8-5e542ecdf66b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install SoccerNet --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490ba6a-76c0-4f2c-8605-ab380db57ca8",
   "metadata": {},
   "source": [
    "We will use the _SoccerNetDownloader_ tool for installing the dataset. To do this we declare the path were we want the dataset to be stored. \n",
    "\n",
    "For this download we need to adquire a **license of use** through this [link](https://docs.google.com/forms/d/e/1FAIpQLSfYFqjZNm4IgwGnyJXDPk2Ko_lZcbVtYX73w5lf6din5nxfmA/viewform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ffd5938-f5ed-48ec-8f09-3abd98d174c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SoccerNet\n",
    "\n",
    "from SoccerNet.Downloader import SoccerNetDownloader\n",
    "mySoccerNetDownloader = SoccerNetDownloader(LocalDirectory=\"../data\")\n",
    "psswrd = \"s0cc3rn3t\"\n",
    "mySoccerNetDownloader.password = psswrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1bfb2b-4a1f-45d1-b197-f35a1a1f5ccb",
   "metadata": {},
   "source": [
    "In this dataset we will find:\n",
    "\n",
    "- train: Standard training data for models, with complete annotations.\n",
    "- valid: Validation data to evaluate performance during development.\n",
    "- test: Test data with non-public labels (typically used for competitions).\n",
    "- challenge: A subset of data specific to official competition or specific challenges, such as Multi-View Foul Recognition.\n",
    "\n",
    "We need the dataset related withe *Multi-view Foul Recognition* challenge, known as __mvfouls__. Also we will download only videos in 720p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbb921-bf3d-4d47-9370-3361786546c4",
   "metadata": {},
   "source": [
    "**IMPORTANT: by executing the following code the installation will start, it can last a long time, so be sure of executing it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d40e07-68af-4834-b05e-29e609a66661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading ../data\\mvfouls\\train_720p.zip...: : 13.3GiB [14:30, 15.2MiB/s]                                            \n",
      "Downloading ../data\\mvfouls\\valid_720p.zip...: : 1.85GiB [02:05, 14.7MiB/s]                                            \n",
      "Downloading ../data\\mvfouls\\test_720p.zip...: : 1.45GiB [01:42, 14.1MiB/s]                                             \n",
      "Downloading ../data\\mvfouls\\challenge_720p.zip...: : 1.37GiB [01:31, 14.9MiB/s]                                        \n"
     ]
    }
   ],
   "source": [
    "mySoccerNetDownloader.downloadDataTask(task=\"mvfouls\", split=[\"train\",\"valid\",\"test\",\"challenge\"], password = psswrd, version = \"720p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bda05b-7698-4b3f-a28e-52f912867072",
   "metadata": {},
   "source": [
    "The dataset will be downloaded in _.zip_ files, which must be **unzipped**.\n",
    "\n",
    "The dataset consists of **3,901 actions**. Each action is composed of at least two videos showing the live action and at least one replay.\n",
    "\n",
    "The dataset is divided into:\n",
    "- Training set (2916 actions).\n",
    "- Validation set (411 actions).\n",
    "- Test set (301 actions).\n",
    "- Challenge set (273 actions without the annotations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e9fad-9aa3-48eb-9d20-13fd798bd08d",
   "metadata": {},
   "source": [
    "We will then use _OpenCV_ to check that the videos and tags have been downloaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6ddedc-cf39-4492-965b-94f46af81ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "train_dataset_path = \"../data/mvfouls/train_720p\"\n",
    "\n",
    "training_videos_path = os.path.join(train_dataset_path)\n",
    "example_video = os.path.join(training_videos_path, \"action_1/clip_0.mp4\")\n",
    "\n",
    "def visualize_video(video_path, num_frames=100):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"No se pudo abrir el video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened() and frame_count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Fin del video o error al leer el frame.\")\n",
    "            break\n",
    "        \n",
    "        cv2.imshow('Video Frame', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "visualize_video(example_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fbd09-ae6d-4432-9195-b5b378a3927e",
   "metadata": {},
   "source": [
    "We will also verify that the tags are in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee329b86-8b66-4199-b85a-e730fb6fa506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de acciones etiquetadas: 2916\n",
      "Índice de la acción: 0\n",
      "Detalles de la acción: {'UrlLocal': 'england_epl\\\\2014-2015\\\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley', 'Offence': 'Offence', 'Contact': 'With contact', 'Bodypart': 'Upper body', 'Upper body part': 'Use of shoulder', 'Action class': 'Challenge', 'Severity': '1.0', 'Multiple fouls': '', 'Try to play': '', 'Touch ball': '', 'Handball': 'No handball', 'Handball offence': '', 'Clips': [{'Url': 'Dataset/Train/action_0/clip_0', 'Camera type': 'Main camera center', 'Timestamp': 1730826, 'Replay speed': 1.0}, {'Url': 'Dataset/Train/action_0/clip_1', 'Camera type': 'Close-up player or field referee', 'Timestamp': 1744173, 'Replay speed': 1.8}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "labels_path = os.path.join(train_dataset_path, \"annotations.json\")\n",
    "\n",
    "with open(labels_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total de acciones etiquetadas: {data['Number of actions']}\")\n",
    "for action_index, action_data in data['Actions'].items():\n",
    "    print(f\"Índice de la acción: {action_index}\")\n",
    "    print(f\"Detalles de la acción: {action_data}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f41700-1247-4324-ad2a-5b2ff4dd0bda",
   "metadata": {},
   "source": [
    "We will extract the information of three actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c21787d-8951-4801-9bdc-60e0f2d4c3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acción número 0:\n",
      "  > Ofensa: Offence\n",
      "  > Parte del cuerpo: Upper body\n",
      "  > Tipo de acción: Challenge\n",
      "  > Severidad: 1.0\n",
      "    - Clip - Main camera center: Dataset/Train/action_0/clip_0 @ 1730826ms\n",
      "    - Clip - Close-up player or field referee: Dataset/Train/action_0/clip_1 @ 1744173ms\n",
      "Acción número 1:\n",
      "  > Ofensa: Offence\n",
      "  > Parte del cuerpo: Under body\n",
      "  > Tipo de acción: Tackling\n",
      "  > Severidad: 3.0\n",
      "    - Clip - Main camera center: Dataset/Train/action_1/clip_0 @ 2400217ms\n",
      "    - Clip - Close-up player or field referee: Dataset/Train/action_1/clip_1 @ 2415695ms\n",
      "Acción número 2:\n",
      "  > Ofensa: Offence\n",
      "  > Parte del cuerpo: Under body\n",
      "  > Tipo de acción: Standing tackling\n",
      "  > Severidad: 3.0\n",
      "    - Clip - Main camera center: Dataset/Train/action_2/clip_0 @ 206821ms\n",
      "    - Clip - Close-up player or field referee: Dataset/Train/action_2/clip_1 @ 230429ms\n",
      "    - Clip - Close-up player or field referee: Dataset/Train/action_2/clip_2 @ 238257ms\n"
     ]
    }
   ],
   "source": [
    "actions = data['Actions']\n",
    "\n",
    "count = 3\n",
    "\n",
    "for action_id, action in actions.items():\n",
    "    print(f\"Acción número {action_id}:\")\n",
    "    print(f\"  > Ofensa: {action['Offence']}\")\n",
    "    print(f\"  > Parte del cuerpo: {action['Bodypart']}\")\n",
    "    print(f\"  > Tipo de acción: {action['Action class']}\")\n",
    "    print(f\"  > Severidad: {action['Severity']}\")\n",
    "    \n",
    "    for clip in action['Clips']:\n",
    "        clip_url = clip['Url']\n",
    "        camera_type = clip['Camera type']\n",
    "        timestamp = clip['Timestamp']\n",
    "        print(f\"    - Clip - {camera_type}: {clip_url} @ {timestamp}ms\")\n",
    "    count -= 1\n",
    "    if count == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62aa32-4d29-49c8-bd7f-1392a6e81ecc",
   "metadata": {},
   "source": [
    "In this fragment we will show both clips of an action currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4434a2dc-836a-4f8a-888e-d2bc206fa5c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "train_dataset_path = \"../data/mvfouls/train_720p\"\n",
    "\n",
    "clip_0_path = os.path.join(train_dataset_path, \"action_1/clip_0.mp4\")\n",
    "clip_1_path = os.path.join(train_dataset_path, \"action_1/clip_1.mp4\")\n",
    "\n",
    "\n",
    "def visualize_clips_synchronized(clip_1_path, clip_2_path, timestamp_1=0, timestamp_2=0, num_frames=100):\n",
    "    cap1 = cv2.VideoCapture(clip_1_path)\n",
    "    cap2 = cv2.VideoCapture(clip_2_path)\n",
    "    \n",
    "    if not cap1.isOpened() or not cap2.isOpened():\n",
    "        print(f\"Error al abrir los videos: {clip_1_path}, {clip_2_path}\")\n",
    "        return\n",
    "\n",
    "    fps1 = cap1.get(cv2.CAP_PROP_FPS)\n",
    "    fps2 = cap2.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    start_frame_1 = int(timestamp_1 / 1000 * fps1)\n",
    "    start_frame_2 = int(timestamp_2 / 1000 * fps2)\n",
    "\n",
    "    cap1.set(cv2.CAP_PROP_POS_FRAMES, start_frame_1)\n",
    "    cap2.set(cv2.CAP_PROP_POS_FRAMES, start_frame_2)\n",
    "\n",
    "    frame_count = 0\n",
    "    while frame_count < num_frames:\n",
    "        ret1, frame1 = cap1.read()\n",
    "        ret2, frame2 = cap2.read()\n",
    "\n",
    "        if not ret1 or not ret2:\n",
    "            print(\"Fin de uno de los videos o error al leer el frame.\")\n",
    "            break\n",
    "\n",
    "        combined_frame = cv2.hconcat([frame1, frame2])\n",
    "        cv2.imshow('Clips Sincronizados', combined_frame)\n",
    "\n",
    "        if cv2.waitKey(int(1000 / max(fps1, fps2))) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "visualize_clips_synchronized(clip_0_path, clip_1_path, timestamp_1=0, timestamp_2=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93bbdd3-b9e8-45ad-bf92-1d79f04b8fd5",
   "metadata": {},
   "source": [
    "In future notebooks we will study the dataset in more detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
